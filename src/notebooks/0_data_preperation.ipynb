{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we use our own external modules, we need the folder src to be in the PYTHONPATH env variable.\n",
    "# However we do not expect the reader to add that folder to the env variable,\n",
    "# therefore we manually load it temporarily in each notebook.\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h3\n",
    "from timeit import default_timer as timer\n",
    "import folium\n",
    "from modules.config import PATH_DIR_TRIPS_RAW, PATH_TRIPS, H3_RESOLUTION, H3_RESOLUTION_DOWNSCALING_QUANTILES, PATH_HEXAGON_RESOLUTION_MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation\n",
    "## Collect & Merge\n",
    "Our dataset consists of multiple csv files. In order to process all of them simultaneously, we merge them together in one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully merged csv data into one dataframe in 3.08 seconds\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "dfs = []\n",
    "for root, subdirs, files in os.walk(PATH_DIR_TRIPS_RAW):\n",
    "    for file in files:\n",
    "        path_to_csv = os.path.join(root, file)\n",
    "        df = pd.read_csv(path_to_csv)\n",
    "        dfs.append(df)\n",
    "\n",
    "trips_raw = pd.concat(dfs)\n",
    "\n",
    "end = timer()\n",
    "print(f\"Succesfully merged csv data into one dataframe in {(end - start):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1055091 entries, 0 to 5079\n",
      "Data columns (total 24 columns):\n",
      " #   Column               Non-Null Count    Dtype  \n",
      "---  ------               --------------    -----  \n",
      " 0   id                   1055091 non-null  object \n",
      " 1   provider             1055091 non-null  object \n",
      " 2   city                 1055091 non-null  object \n",
      " 3   vehicleType          1055091 non-null  object \n",
      " 4   model                616634 non-null   object \n",
      " 5   datetime_start       1055091 non-null  object \n",
      " 6   date_start           1055091 non-null  int64  \n",
      " 7   time_start           1055091 non-null  int64  \n",
      " 8   datetime_end         1055091 non-null  object \n",
      " 9   date_end             1055091 non-null  int64  \n",
      " 10  time_end             1055091 non-null  int64  \n",
      " 11  longitude_start      1055091 non-null  float64\n",
      " 12  latitude_start       1055091 non-null  float64\n",
      " 13  longitude_end        1055091 non-null  float64\n",
      " 14  latitude_end         1055091 non-null  float64\n",
      " 15  fuel_start           1012351 non-null  float64\n",
      " 16  fuel_end             1012351 non-null  float64\n",
      " 17  distance             1055091 non-null  float64\n",
      " 18  duration             1055091 non-null  float64\n",
      " 19  price_driving_start  968188 non-null   object \n",
      " 20  price_driving_end    971080 non-null   object \n",
      " 21  price_promo_start    2959 non-null     object \n",
      " 22  price_promo_end      61 non-null       object \n",
      " 23  missing_file_number  1055091 non-null  int64  \n",
      "dtypes: float64(8), int64(5), object(11)\n",
      "memory usage: 201.2+ MB\n"
     ]
    }
   ],
   "source": [
    "trips_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relevant columns (id, provider, vehicleType, datetime_start, datetime_end, longitude_start, longitude_end, latitude_start, latitude_end, distance) do not have any null values. Therefore we do not have to perform any deletion or imputation strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = pd.concat([trips_raw['longitude_start'], trips_raw['longitude_end']])\n",
    "lats = pd.concat([trips_raw['latitude_start'], trips_raw['latitude_end']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_min = lats.min()\n",
    "lat_max = lats.max()\n",
    "lon_min = lons.min()\n",
    "lon_max = lons.max()\n",
    "\n",
    "points = [(lat_max, lon_min), (lat_min, lon_min), (lat_min, lon_max), (lat_max, lon_max), (lat_max, lon_min)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe src=\"about:blank\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" data-html=%3C%21DOCTYPE%20html%3E%0A%3Chead%3E%20%20%20%20%0A%20%20%20%20%3Cmeta%20http-equiv%3D%22content-type%22%20content%3D%22text/html%3B%20charset%3DUTF-8%22%20/%3E%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%3Cscript%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20L_NO_TOUCH%20%3D%20false%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20L_DISABLE_3D%20%3D%20false%3B%0A%20%20%20%20%20%20%20%20%3C/script%3E%0A%20%20%20%20%0A%20%20%20%20%3Cstyle%3Ehtml%2C%20body%20%7Bwidth%3A%20100%25%3Bheight%3A%20100%25%3Bmargin%3A%200%3Bpadding%3A%200%3B%7D%3C/style%3E%0A%20%20%20%20%3Cstyle%3E%23map%20%7Bposition%3Aabsolute%3Btop%3A0%3Bbottom%3A0%3Bright%3A0%3Bleft%3A0%3B%7D%3C/style%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//cdn.jsdelivr.net/npm/leaflet%401.6.0/dist/leaflet.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//code.jquery.com/jquery-1.12.4.min.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js%22%3E%3C/script%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdn.jsdelivr.net/npm/leaflet%401.6.0/dist/leaflet.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css%22/%3E%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%3Cmeta%20name%3D%22viewport%22%20content%3D%22width%3Ddevice-width%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20initial-scale%3D1.0%2C%20maximum-scale%3D1.0%2C%20user-scalable%3Dno%22%20/%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20%3Cstyle%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23map_b51c9411494c4f87b3690c35d269fe8c%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20position%3A%20relative%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20width%3A%20100.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20height%3A%20100.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20left%3A%200.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20top%3A%200.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%3C/style%3E%0A%20%20%20%20%20%20%20%20%0A%3C/head%3E%0A%3Cbody%3E%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%3Cdiv%20class%3D%22folium-map%22%20id%3D%22map_b51c9411494c4f87b3690c35d269fe8c%22%20%3E%3C/div%3E%0A%20%20%20%20%20%20%20%20%0A%3C/body%3E%0A%3Cscript%3E%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20var%20map_b51c9411494c4f87b3690c35d269fe8c%20%3D%20L.map%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22map_b51c9411494c4f87b3690c35d269fe8c%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20center%3A%20%5B50.9253%2C%206.9495%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20crs%3A%20L.CRS.EPSG3857%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20zoom%3A%2011%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20zoomControl%3A%20true%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20preferCanvas%3A%20false%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%29%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20L.control.scale%28%29.addTo%28map_b51c9411494c4f87b3690c35d269fe8c%29%3B%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20var%20tile_layer_788d4e91b6344ab1b666e13697eb2d23%20%3D%20L.tileLayer%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22https%3A//%7Bs%7D.tile.openstreetmap.org/%7Bz%7D/%7Bx%7D/%7By%7D.png%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%22attribution%22%3A%20%22Data%20by%20%5Cu0026copy%3B%20%5Cu003ca%20href%3D%5C%22http%3A//openstreetmap.org%5C%22%5Cu003eOpenStreetMap%5Cu003c/a%5Cu003e%2C%20under%20%5Cu003ca%20href%3D%5C%22http%3A//www.openstreetmap.org/copyright%5C%22%5Cu003eODbL%5Cu003c/a%5Cu003e.%22%2C%20%22detectRetina%22%3A%20false%2C%20%22maxNativeZoom%22%3A%2020%2C%20%22maxZoom%22%3A%2020%2C%20%22minZoom%22%3A%200%2C%20%22noWrap%22%3A%20false%2C%20%22opacity%22%3A%201%2C%20%22subdomains%22%3A%20%22abc%22%2C%20%22tms%22%3A%20false%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%29.addTo%28map_b51c9411494c4f87b3690c35d269fe8c%29%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20var%20poly_line_556b31299118423cab45af7ef91f79e4%20%3D%20L.polyline%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5B%5B51.03007%2C%206.807150999999999%5D%2C%20%5B50.835495%2C%206.807150999999999%5D%2C%20%5B50.835495%2C%207.11707%5D%2C%20%5B51.03007%2C%207.11707%5D%2C%20%5B51.03007%2C%206.807150999999999%5D%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%22bubblingMouseEvents%22%3A%20true%2C%20%22color%22%3A%20%22%233388ff%22%2C%20%22dashArray%22%3A%20null%2C%20%22dashOffset%22%3A%20null%2C%20%22fill%22%3A%20false%2C%20%22fillColor%22%3A%20%22%233388ff%22%2C%20%22fillOpacity%22%3A%200.2%2C%20%22fillRule%22%3A%20%22evenodd%22%2C%20%22lineCap%22%3A%20%22round%22%2C%20%22lineJoin%22%3A%20%22round%22%2C%20%22noClip%22%3A%20false%2C%20%22opacity%22%3A%201.0%2C%20%22smoothFactor%22%3A%201.0%2C%20%22stroke%22%3A%20true%2C%20%22weight%22%3A%203%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%29.addTo%28map_b51c9411494c4f87b3690c35d269fe8c%29%3B%0A%20%20%20%20%20%20%20%20%0A%3C/script%3E onload=\"this.contentDocument.open();this.contentDocument.write(    decodeURIComponent(this.getAttribute('data-html')));this.contentDocument.close();\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7f08ed1a2820>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmap = folium.Map(location=(50.9253, 6.9495), zoom_start=11, control_scale=True, max_zoom=20)\n",
    "folium.PolyLine(points).add_to(fmap)\n",
    "fmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All trips starting and ending locations fall within the blue square. This seems plausible, so there are no outliers in the geospatial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string time columns to datetime format\n",
    "trips_raw['datetime_start'] =  pd.to_datetime(trips_raw['datetime_start'], format='%Y%m%d-%H%M%S')\n",
    "trips_raw['datetime_end'] =  pd.to_datetime(trips_raw['datetime_end'], format='%Y%m%d-%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_raw[\"start\"] = list(zip(trips_raw[\"latitude_start\"],trips_raw[\"longitude_start\"]))\n",
    "trips_raw[\"end\"] = list(zip(trips_raw[\"latitude_end\"],trips_raw[\"longitude_end\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_raw[\"vehicleType\"] = trips_raw[\"vehicleType\"].replace(\n",
    "    {\"kick scooter\": \"kick_scooter\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To properly examine the geospatial data we will use the library H3, which is a \"Hexagonal Hierarchical Spatial Index\". This means that the surface of the earth is split into hexagons. We can use these hexagons to easily group spatial data, like our trips starting and end points.  \n",
    "H3 also provides different resolutions. Choosing a higher resolution results in smaller hexagons, which in our case leads to a more realistic model. However more hexagons also increase the computional power required to create and solve the problem.  \n",
    "The H3 Resolution is configurable in the `config.py`. For regular hardware we recommand a resultion of 7 (~80 regions) or 6 (~16 regions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assigned h3 hex ids in 30.50 seconds\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "trips_raw[\"start_hex_id\"] = trips_raw.apply(\n",
    "    lambda row: h3.geo_to_h3(row.latitude_start, row.longitude_start, H3_RESOLUTION),\n",
    "    axis=1,\n",
    ")\n",
    "trips_raw[\"end_hex_id\"] = trips_raw.apply(\n",
    "    lambda row: h3.geo_to_h3(row.latitude_end, row.longitude_end, H3_RESOLUTION),\n",
    "    axis=1,\n",
    ")\n",
    "end = timer()\n",
    "print(f\"assigned h3 hex ids in {(end - start):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of regions will have a large influence on the dimensionality of the linear program underlying our model. Therefore a large number of regions will result in long runtimes. To reduce the number of regions we have to decrease the h3 resolution. A smaller resolution will however also result in bigger regions, which decreases to accuracy of our model.  \n",
    "Choosing a single resolution for all of our data leads to some regions at the border of cologne that have very little demand. It is not necessary for these regions to have the same resolution as the inner regions, where most demand is happening.  \n",
    "Therefore we will downscale (decrease the h3 resolution) for regions that have a low number of incoming and outgoing trips. This downscaling in configurable with the `H3_RESOLUTION_DOWNSCALING_QUANTILES` variable in the `settings.py` file.  \n",
    "The length of the array determines how often we downscale from the initial `H3_RESOLUTION`. Each entry in the array represents the quantil of regions with the lowest demand, which willbe downscaled.  \n",
    "E.g. `H3_RESOLUTION = 8` and `H3_RESOLUTION_DOWNSCALING_QUANTILES = [0.9, 0.75]` would mean that we first calculate the hexagons of resolution 8 for all regions and then downscale 90% of the regions with the lowest number of outgoing and incoming trips. We would then repeat the process and downscale 75% of all regions with resolution 7.  \n",
    "A visualization of the result is available in 1. descriptive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of regions before downscaling: 82\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of regions before downscaling: {trips_raw['start_hex_id'].append(trips_raw['end_hex_id']).nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_raw[\"start_resolution\"] = H3_RESOLUTION\n",
    "trips_raw[\"end_resolution\"] = H3_RESOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downscaling resolution 7 to 6 for all regions in 0.9-quantile\n",
      "80 in current resolution\n",
      "total number of (start) regions before current downscale: 80\n",
      "total number of (start) regions after current downscale: 27\n",
      "231964 trips have downscaled region\n",
      "downscaled 1 resolutions in 7.70 seconds\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "for i, quantile in enumerate(H3_RESOLUTION_DOWNSCALING_QUANTILES):\n",
    "    print(f\"downscaling resolution {H3_RESOLUTION-i} to {H3_RESOLUTION-i-1} for all regions in {quantile}-quantile\")\n",
    "    trips_by_start_hex = trips_raw[trips_raw[\"start_resolution\"] == H3_RESOLUTION - i]\\\n",
    "        .groupby(\"start_hex_id\").size()\n",
    "    trips_by_end_hex = trips_raw[trips_raw[\"start_resolution\"] == H3_RESOLUTION - i]\\\n",
    "        .groupby(\"start_hex_id\").size()\n",
    "    trips_by_hex = trips_by_start_hex.add(trips_by_end_hex, fill_value=0)\n",
    "    print(f\"{len(trips_by_hex)} in current resolution\")\n",
    "    cutoff = trips_by_hex.quantile(quantile)\n",
    "    to_parent_hex = trips_by_hex[trips_by_hex < cutoff].index\n",
    "    parent_remap = {child: h3.h3_to_parent(child) for child in to_parent_hex}\n",
    "\n",
    "    print(f\"total number of (start) regions before current downscale: {trips_raw['start_hex_id'].nunique()}\")\n",
    "    trips_raw[\"start_hex_id\"] = trips_raw[\"start_hex_id\"].replace(parent_remap)\n",
    "    trips_raw[\"end_hex_id\"] = trips_raw[\"end_hex_id\"].replace(parent_remap)\n",
    "    print(f\"total number of (start) regions after current downscale: {trips_raw['start_hex_id'].nunique()}\")\n",
    "\n",
    "    print(f\"{trips_raw['start_hex_id'].isin(parent_remap.values()).sum()} trips have downscaled region\")\n",
    "    trips_raw.loc[trips_raw['start_hex_id'].isin(parent_remap.values()), 'start_resolution'] = H3_RESOLUTION - i - 1\n",
    "    trips_raw.loc[trips_raw['end_hex_id'].isin(parent_remap.values()), 'end_resolution'] = H3_RESOLUTION - i - 1\n",
    "end = timer()\n",
    "print(f\"downscaled {len(H3_RESOLUTION_DOWNSCALING_QUANTILES)} resolutions in {(end - start):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remaining regions after downscaling: 29\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of remaining regions after downscaling: {trips_raw['start_hex_id'].append(trips_raw['end_hex_id']).nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to save the resolution of each hexagon that is used, because our model will use the resolution to calculate the distances of round trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_per_start_hex_id = trips_raw[['start_hex_id', 'start_resolution']].groupby('start_hex_id').first()\\\n",
    "    .rename_axis(index=\"hex_id\").rename(columns={'start_resolution': 'resolution'})\n",
    "res_per_end_hex_id = trips_raw[['end_hex_id', 'end_resolution']].groupby('end_hex_id').first()\\\n",
    "    .rename_axis(index=\"hex_id\").rename(columns={'end_resolution': 'resolution'})\n",
    "res_per_hex_id = res_per_end_hex_id.append(res_per_start_hex_id).reset_index().drop_duplicates()\n",
    "res_per_hex_id = res_per_hex_id.set_index('hex_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To persist data between notebooks we save dataframes to the pickle format.  \n",
    "The pickle format has the advantage that it can serialize data and therefore we can easily save python specific datatypes like datetimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully saved dataframe to pickle in 1.43 seconds\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "os.makedirs(os.path.dirname(PATH_HEXAGON_RESOLUTION_MAP), exist_ok=True)\n",
    "res_per_hex_id.to_pickle(PATH_HEXAGON_RESOLUTION_MAP)\n",
    "\n",
    "os.makedirs(os.path.dirname(PATH_TRIPS), exist_ok=True)\n",
    "trips_raw.to_pickle(PATH_TRIPS)\n",
    "end = timer()\n",
    "print(f\"Succesfully saved dataframe to pickle in {(end - start):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "921dce5431bc8dd5032dbf768a24c906ac17844f87e0f443ecd3f0f6d3f457c9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('VR': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}