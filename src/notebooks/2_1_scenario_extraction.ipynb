{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# As we use our own external modules, we need the folder src to be in the PYTHONPATH env variable.\n",
    "# However we do not expect the reader to add that folder to the env variable,\n",
    "# therefore we manually load it temporarily in each notebook.\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from timeit import default_timer as timer\n",
    "import pandas as pd\n",
    "from modules.config import PATH_TRIPS, PERIOD_DURATION, PATH_TRIPS_GROUPED"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scenario Extraction\n",
    "In this notebook we will convert the given dataset into data that our model can process.  \n",
    "One entry of the dataset currently represents one trip. So the most important columns are the trip's starting and ending location and time, as well as the vehicle type of the vehicle that was used for the trip.  \n",
    "We will now aggregate that data so that the resulting data represents the number of trips made with a certain vehicle type in a certain time period, starting in a certain region, ending in a certain region.  \n",
    "We will use the aggregated data as the demand for our model.  \n",
    "  \n",
    "$ d_{ijtm} $  \n",
    "where $i$ and $j$ are the starting and ending regions, $t$ is the time period , $m$ is the vehicle and $d$ is the number of trips."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trips = pd.read_pickle(PATH_TRIPS)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Assign each trip a certain period $t$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trips['datetime_start_floored'] = trips['datetime_start'].dt.floor('%dH' % PERIOD_DURATION)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Group trips by regions $i$ $j$, period $t$ and vehicle type $m$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trips_grouped = (\n",
    "    trips.groupby(\n",
    "        [\"vehicleType\", \"start_hex_id\", \"end_hex_id\", \"datetime_start_floored\"]\n",
    "    )\n",
    "    .size()\n",
    "    .to_frame(\"demand\")\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Currently we only have entries, where the number of trips is larger than 0. However we want to have entries for every $t$,$i$,$j$ and $m$. Therefore we reindex the dataframe.  \n",
    "We also check that we do not change any existing entries, by comparing the values before and after the reindex for a sample entry."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sanity_index = trips_grouped.index[0]\n",
    "sanity_check_entry_1 = trips_grouped.loc[sanity_index][0]\n",
    "\n",
    "\n",
    "full_index = pd.MultiIndex.from_product([\n",
    "    trips['vehicleType'].unique(),\n",
    "    trips['start_hex_id'].unique(), \n",
    "    trips['end_hex_id'].unique(),\n",
    "    trips['datetime_start_floored'].unique(),\n",
    "])\n",
    "\n",
    "trips_grouped = trips_grouped.reindex(full_index)\n",
    "trips_grouped = trips_grouped.fillna(0)\n",
    "\n",
    "sanity_check_entry_2 = trips_grouped.loc[sanity_index][0]\n",
    "sanity_check = sanity_check_entry_1 == sanity_check_entry_2\n",
    "\n",
    "print(\"sanity check: \" + \"️️✔️\" if sanity_check else \"❌\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sanity check: ️️✔️\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trips_grouped = trips_grouped.reset_index(level=0).rename(columns={\"level_0\": \"vehicle_type\"})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now move the vehicle type column to the index, so that our index represents $i$, $j$, $t$ and $m$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "demand_dict = {}\n",
    "for vehicle_type in trips_grouped['vehicle_type'].unique():\n",
    "    demand_dict[vehicle_type] = trips_grouped[trips_grouped['vehicle_type'] == vehicle_type]['demand']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trips_seperated = pd.DataFrame(demand_dict)\n",
    "\n",
    "sanity_vehicle_type = list(sanity_index)[0]\n",
    "sanity_index_short = list(sanity_index)[1:]\n",
    "\n",
    "sanity_check_entry_3 = trips_seperated.loc[tuple(sanity_index_short), sanity_vehicle_type]\n",
    "sanity_check = sanity_check_entry_2 == sanity_check_entry_3\n",
    "\n",
    "print(\"sanity check: \" + \"️️✔️\" if sanity_check else \"❌\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sanity check: ️️✔️\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trips_seperated.head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                     kick_scooter  bicycle  \\\n",
       "871fa199affffff 871fa199affffff 2019-12-29 00:00:00          15.0      0.0   \n",
       "                                2019-12-29 08:00:00          20.0      1.0   \n",
       "                                2019-12-29 16:00:00          22.0      0.0   \n",
       "\n",
       "                                                      car  \n",
       "871fa199affffff 871fa199affffff 2019-12-29 00:00:00   2.0  \n",
       "                                2019-12-29 08:00:00  12.0  \n",
       "                                2019-12-29 16:00:00  12.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>kick_scooter</th>\n",
       "      <th>bicycle</th>\n",
       "      <th>car</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">871fa199affffff</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">871fa199affffff</th>\n",
       "      <th>2019-12-29 00:00:00</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 08:00:00</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 16:00:00</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We save the resulting data as a pickle file. The data is now  in the correct format (except for scenario tree structure) for our model. We will use now use this data to generate a arbitrary number of scenarios and simultaneously ensure that the generated scenarios represent a scenario tree. This basically means that for the first period all demand values are the same (root of the scenario tree) and for subsequent periods more and more demand values will differ. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start = timer()\n",
    "\n",
    "os.makedirs(os.path.dirname(PATH_TRIPS_GROUPED), exist_ok=True)\n",
    "trips_seperated.to_pickle(PATH_TRIPS_GROUPED)\n",
    "\n",
    "end = timer()\n",
    "print(f\"Succesfully saved dataframe to pickle in {(end - start):.2f} seconds\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Succesfully saved dataframe to pickle in 0.01 seconds\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trips_seperated.reset_index().nunique()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "level_0          27\n",
       "level_1          29\n",
       "level_2         305\n",
       "kick_scooter    498\n",
       "bicycle          30\n",
       "car              62\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "055d270bd58aa3d80f7b485d27649a16e4c7a108491a44738b1a4fa2b5d0a91f"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('VEHICLE_REPOSITION': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}