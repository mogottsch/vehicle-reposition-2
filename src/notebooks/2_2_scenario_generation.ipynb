{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# As we use our own external modules, we need the folder src to be in the PYTHONPATH env variable.\n",
    "# However we do not expect the reader to add that folder to the env variable,\n",
    "# therefore we manually load it temporarily in each notebook.\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy.stats import poisson\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "from modules.config import (\n",
    "    PATH_TRIPS_GROUPED,\n",
    "    PERIOD_DURATION,\n",
    "    N_SCENARIOS,\n",
    "    N_REALIZATIONS,\n",
    "    PATH_SCENARIOS,\n",
    "    MODE_IS_WEEKEND,\n",
    ")\n",
    "from modules.helpers import format_bytes\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scenario Generation\n",
    "In this notebook we will use the previously aggregated trip data to generate an arbitrary amound of scenarios while also ensuring the scenario tree structure of the generated scenarios.  \n",
    "\n",
    "#### A scenario tree where each node has two branches\n",
    "![Scenario Tree](../resources/tree.png)  \n",
    "Each branch in a scenario tree corresponds to a possible realiziation of a random variable.  \n",
    "In our case, the number of realization is configurable in the `config.py`.\n",
    "<hr>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start by reading the grouped trip data from the pickle file.  \n",
    "We also add the `is_weekend` column. As we will only use scenario data from either weekends or weekdays.  \n",
    "This weekend decision is configurable in the `config.py`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trips = pd.read_pickle(PATH_TRIPS_GROUPED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trips = trips.rename_axis(['start_hex_id', 'end_hex_id', 'daytime']).reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trips['is_weekend'] = trips['daytime'].dt.dayofweek > 4\n",
    "trips['time'] = trips['daytime'].dt.time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To generate scenarios we will use the poisson distribution.    \n",
    "As the estimator we use the maximum likelihood estimate of the poisson distribution, which is the mean.  \n",
    "So for a n samples $ k_i \\in \\mathbb{N} $ for $ i =1,..,n $, we get the maximum likelihood estimate with:  \n",
    "$ \\lambda_{MLE} = \\frac{1}{n}\\sum_{i=1}^{n}k_i$\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mu = trips.drop('daytime', axis=1) \\\n",
    "          .groupby(['is_weekend', 'time', 'start_hex_id', 'end_hex_id']) \\\n",
    "          .mean()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To ensure the tree structure we have to generate increaslingly more demand values for subsequent time periods. e.g. if the number of realiziations is equal to 2, we would generate only 1 demand value for the first period, 2 for the second period, 4 for the third, 8 for the fourth and so on...  \n",
    "If there were only demand value per time period and we would have 3 time period with 2 realizations each, then the demand values (in scenario tree structure) could be represented by the following matrix.\n",
    "$$ \\begin{pmatrix}\n",
    "2 & 3 & 2\\\\\n",
    "2 & 3 & 3\\\\\n",
    "2 & 4 & 1\\\\\n",
    "2 & 4 & 2\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "  \n",
    "Let $r$ be the number of realizations of each random variable, $d$ the duration of each period, $n$ the number of scenarios and $t$ a specific time interval.  \n",
    "So for example:  \n",
    "$r = 2, d=4, n=32, t \\in \\{0, 4, 8, 12, 16, 20\\}$  \n",
    "Then we can calculate the number of differing scenarios (scenario groups) for a specific time interval with:  \n",
    "$\\Large r^{\\frac{t}{d}}$  \n",
    "Also we can calculate the number of scenarios in each group with:  \n",
    "$\\Large\\frac{n}{r^{\\frac{h}{d}}}$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trips['time'].unique()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([datetime.time(0, 0), datetime.time(8, 0), datetime.time(16, 0)],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "hours_list = list(map(lambda time: time.hour,trips['time'].unique()))\n",
    "# TODO rename these variables!\n",
    "batch_map = {\n",
    "    hour: {\n",
    "        'n_batches': N_REALIZATIONS**(int(hour / PERIOD_DURATION)),\n",
    "        'batch_size': int(N_SCENARIOS / N_REALIZATIONS**(hour/PERIOD_DURATION)),\n",
    "    }\n",
    "    for hour in hours_list\n",
    "}\n",
    "batch_map"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: {'n_batches': 1, 'batch_size': 9},\n",
       " 8: {'n_batches': 3, 'batch_size': 3},\n",
       " 16: {'n_batches': 9, 'batch_size': 1}}"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start = timer()\n",
    "scenario_dict = {}\n",
    "for [[time, start_hex_id, end_hex_id], [mu_kick_scooter, mu_car, mu_bicycle]] in mu.loc[\n",
    "    MODE_IS_WEEKEND,\n",
    "].iterrows():\n",
    "    n_batches, batch_size = batch_map[time.hour].values()\n",
    "\n",
    "    kick_scooter_scenarios = np.repeat(\n",
    "        poisson.rvs(mu_kick_scooter, size=n_batches, random_state=42), batch_size\n",
    "    )\n",
    "    car_scenarios = np.repeat(\n",
    "        poisson.rvs(mu_car, size=n_batches, random_state=42), batch_size\n",
    "    )\n",
    "    bicycle_scenarios = np.repeat(\n",
    "        poisson.rvs(mu_bicycle, size=n_batches, random_state=42), batch_size\n",
    "    )\n",
    "    \n",
    "    scenario_dict[\n",
    "        (start_hex_id, end_hex_id, time, \"kick_scooter\")\n",
    "    ] = kick_scooter_scenarios\n",
    "    scenario_dict[(start_hex_id, end_hex_id, time, \"bicycle\")] = bicycle_scenarios\n",
    "    scenario_dict[(start_hex_id, end_hex_id, time, \"car\")] = car_scenarios\n",
    "\n",
    "end = timer()\n",
    "print(f\"Succesfully generated {N_SCENARIOS} scenarios in {(end - start):.2f} seconds\")\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'True: boolean label can not be used without a boolean index'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8530/484702512.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mscenario_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m for [[time, start_hex_id, end_hex_id], [mu_kick_scooter, mu_car, mu_bicycle]] in mu.loc[\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mMODE_IS_WEEKEND\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ].iterrows():\n",
      "\u001b[0;32m~/miniconda3/envs/VEHICLE_REPOSITION_TWO/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VEHICLE_REPOSITION_TWO/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VEHICLE_REPOSITION_TWO/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0;31m# boolean not in slice and with boolean index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_bool_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m             raise KeyError(\n\u001b[0m\u001b[1;32m    973\u001b[0m                 \u001b[0;34mf\"{key}: boolean label can not be used without a boolean index\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m             )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'True: boolean label can not be used without a boolean index'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `scenarios` dataframe now consists of the configured number of scenarios."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scenarios = pd.DataFrame.from_dict(scenario_dict, orient=\"index\")\n",
    "del scenario_dict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scenarios.index = pd.MultiIndex.from_tuples(scenarios.index)\n",
    "scenarios = scenarios.stack().to_frame()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scenarios.index = scenarios.index.rename(['start_hex_ids', 'end_hex_ids', 'time', 'vehicle_types', 'scenarios'])\n",
    "scenarios = scenarios.rename(columns={0: 'demand'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After transforming the scenarios back to our previous data format we can now save the scenario data as a pickle file.  \n",
    "We could use this data as a direct input for our model, however with a large number of scenarios the Linear Program that is underlying our model can take very long to solve.  \n",
    "Therefore we will reduce the generated scenarios, so that we have a smaller subset that still represents the original dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "os.makedirs(os.path.dirname(PATH_SCENARIOS), exist_ok=True)\n",
    "scenarios.to_pickle(PATH_SCENARIOS)\n",
    "\n",
    "print(f\"scenario filesize: {format_bytes(os.path.getsize(PATH_SCENARIOS))}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "scenario filesize: 807.25 kilobytes\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scenarios.reset_index().nunique()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "start_hex_ids     27\n",
       "end_hex_ids       29\n",
       "time               3\n",
       "vehicle_types      3\n",
       "scenarios          9\n",
       "demand           115\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scenarios.head(3)\n",
    "# free the memory\n",
    "%reset -f\n",
    "import gc\n",
    "gc.collect()\n",
    "# this still does not free all memory for some reason\n",
    "# we recommend to close the notebook after execution or restart\n",
    "# the kernel manually if the amount of generated scenarios is large"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "055d270bd58aa3d80f7b485d27649a16e4c7a108491a44738b1a4fa2b5d0a91f"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('VEHICLE_REPOSITION': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}